"""
Calculate ranked correlation between metrics and forward returns by period
For each period, calculate correlation across all stocks using RANKINGS (not absolute values)
- Both metrics and forward returns are ranked from 1 to n
- Correlation is calculated on the ranks, not the original values
- This is equivalent to Spearman rank correlation
Reads data from metrics.json (generated by get_metrics.py)
"""
import json
import os
import numpy as np
from scipy.stats import pearsonr, spearmanr, rankdata
from typing import List, Tuple, Dict, Optional
import argparse
import re
import warnings

# ============================================================================
# CONSTANTS
# ============================================================================

# Forward return periods to analyze
FORWARD_RETURN_PERIODS = ['total', '1y', '3y', '5y', '10y']

# Keys to exclude when detecting metrics (return metrics are used to evaluate predictive power, not metrics themselves)
EXCLUDED_KEYS = {
    'period', 'price', 'dividends', 'total_return', 'forward_return',
    'forward_return_1y', 'forward_return_3y', 'forward_return_5y', 'forward_return_10y'
}

# Statistical significance threshold
SIGNIFICANCE_THRESHOLD = 0.05

# Metric display names
METRIC_DISPLAY_NAMES = {
    'roa': 'ROA (Return on Assets)',
    'ebit_ppe': 'EBIT/PPE (EBIT per Property, Plant & Equipment)',
    'ebit_ppe_ttm': 'EBIT/PPE TTM (Trailing Twelve Months)'
}


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def get_forward_return_key(forward_period: str) -> str:
    """
    Get the forward return key for a given forward period.
    
    Args:
        forward_period: Forward period identifier ('total', '1y', '3y', '5y', '10y')
    
    Returns:
        The key name for the forward return in the data structure
    """
    if forward_period == 'total':
        return "forward_return"
    else:
        return f"forward_return_{forward_period}"


def format_forward_period_display(forward_period: str) -> str:
    """
    Format forward period for display.
    
    Args:
        forward_period: Forward period identifier
    
    Returns:
        Formatted display string
    """
    if forward_period == 'total':
        return "Total forward return"
    else:
        return f"{forward_period} forward return"


# ============================================================================
# DATA MODEL
# ============================================================================

class MetricData:
    """
    Data model class to hold extracted metric and forward return data.
    Provides efficient access and filtering methods.
    """
    
    def __init__(self):
        """
        Initialize empty MetricData structure.
        Structure: {forward_period: {time_period: {metric_key: [(metric_value, forward_return), ...]}}}
        """
        self.data: Dict[str, Dict[str, Dict[str, List[Tuple[float, float]]]]] = {
            period: {} for period in FORWARD_RETURN_PERIODS
        }
        self.metric_keys: List[str] = []
    
    def add_data_point(self, forward_period: str, time_period: str, metric_key: str, 
                      metric_value: float, forward_return: float):
        """Add a single data point to the structure."""
        if time_period not in self.data[forward_period]:
            self.data[forward_period][time_period] = {}
        if metric_key not in self.data[forward_period][time_period]:
            self.data[forward_period][time_period][metric_key] = []
        self.data[forward_period][time_period][metric_key].append((metric_value, forward_return))
    
    def get_pairs(self, forward_period: str, metric_key: str, time_period: Optional[str] = None) -> List[Tuple[float, float]]:
        """
        Get all (metric_value, forward_return) pairs for a given forward period and metric.
        
        Args:
            forward_period: Forward return period
            metric_key: Metric key
            time_period: Optional time period filter (if None, returns all time periods)
        
        Returns:
            List of (metric_value, forward_return) tuples
        """
        pairs = []
        periods_to_check = [time_period] if time_period else self.data[forward_period].keys()
        
        for tp in periods_to_check:
            if tp in self.data[forward_period] and metric_key in self.data[forward_period][tp]:
                pairs.extend(self.data[forward_period][tp][metric_key])
        
        return pairs
    
    def get_time_periods(self, forward_period: str) -> List[str]:
        """Get all time periods for a given forward period."""
        return sorted([p for p in self.data[forward_period].keys() 
                      if isinstance(p, str) or (isinstance(p, (int, float)) and p != 0)])


# ============================================================================
# DATA LOADING AND EXTRACTION
# ============================================================================

def load_data_from_jsonl(filename: str) -> List[dict]:
    """
    Load stock data from JSONL file (one JSON object per line)
    
    Args:
        filename: Path to JSONL file
        
    Returns:
        List of stock data dictionaries
    """
    if not os.path.exists(filename):
        return []
    
    stocks = []
    try:
        with open(filename, 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    stock = json.loads(line)
                    stocks.append(stock)
                except json.JSONDecodeError:
                    continue
    except Exception:
        return []
    
    return stocks


def get_revenue_at_date(stock_data: dict, target_year: int = 2002) -> Optional[Tuple[float, str]]:
    """
    Get revenue for a stock at a specific date
    
    Args:
        stock_data: Stock data dictionary from JSONL
        target_year: Target year to get revenue
        
    Returns:
        Tuple of (revenue, date_string) or None
    """
    if not stock_data or "data" not in stock_data:
        return None
    
    data = stock_data.get("data", {})
    
    # Try different possible key names for dates
    period_dates = None
    for date_key in ["period_end_date", "fiscal_quarter_key", "original_filing_date"]:
        if date_key in data and data[date_key]:
            period_dates = data[date_key]
            break
    
    if not period_dates or not isinstance(period_dates, list) or len(period_dates) == 0:
        return None
    
    revenues = data.get("revenue", [])
    if not isinstance(revenues, list):
        return None
    
    # Find quarter near target year
    quarter_idx = None
    for idx, date_str in enumerate(period_dates):
        if date_str and isinstance(date_str, str):
            # Try to extract year from date string
            try:
                year = int(date_str[:4])
                if year >= target_year - 1 and year <= target_year + 1:
                    quarter_idx = idx
                    break
            except (ValueError, TypeError):
                continue
    
    if quarter_idx is None:
        return None
    
    # Try to get data at that quarter, or nearby quarters
    for offset in [0, 1, -1, 2, -2, 3, -3, 4, -4]:
        idx = quarter_idx + offset
        if 0 <= idx < len(period_dates) and idx < len(revenues):
            if revenues[idx] is not None and revenues[idx] > 0:
                return (revenues[idx], period_dates[idx])
    
    return None


def get_stocks_with_revenue_over_threshold(threshold: float = 1_000_000_000) -> set:
    """
    Load stocks from JSONL files and return set of symbols with revenue > threshold
    
    Args:
        threshold: Revenue threshold in dollars (default: 1B)
        
    Returns:
        Set of stock symbols that have revenue > threshold
    """
    print(f"Loading stock data to filter by revenue > ${threshold/1e9:.1f}B...")
    
    # Load from both NYSE and NASDAQ
    nyse_stocks = load_data_from_jsonl("data/nyse_data.jsonl")
    nasdaq_stocks = load_data_from_jsonl("data/nasdaq_data.jsonl")
    all_stocks = nyse_stocks + nasdaq_stocks
    
    print(f"  Loaded {len(all_stocks)} stocks from JSONL files")
    
    qualifying_symbols = set()
    qualifying_stocks_data = []  # Store stock data for calculating average years
    
    # Check revenue for each stock
    for stock_data in all_stocks:
        symbol = stock_data.get("symbol", "").upper()
        if not symbol:
            continue
        
        # Try to get revenue around 2002-2004
        revenue_result = None
        for year in range(2002, 2005):
            revenue_result = get_revenue_at_date(stock_data, year)
            if revenue_result:
                break
        
        if revenue_result:
            revenue, _ = revenue_result
            if revenue >= threshold:
                qualifying_symbols.add(symbol)
                qualifying_stocks_data.append(stock_data)
    
    print(f"  Found {len(qualifying_symbols)} stocks with revenue > ${threshold/1e9:.1f}B")
    
    # Calculate average years of data per stock
    if qualifying_stocks_data:
        total_quarters = 0
        for stock_data in qualifying_stocks_data:
            if stock_data and "data" in stock_data:
                data = stock_data.get("data", {})
                # Try different possible key names for dates
                period_dates = None
                for date_key in ["period_end_date", "fiscal_quarter_key", "original_filing_date"]:
                    if date_key in data and data[date_key]:
                        period_dates = data[date_key]
                        break
                if period_dates and isinstance(period_dates, list):
                    total_quarters += len(period_dates)
        
        if len(qualifying_stocks_data) > 0:
            avg_quarters = total_quarters / len(qualifying_stocks_data)
            avg_years = avg_quarters / 4.0
            print(f"  Average years of data per stock: {avg_years:.1f} years ({avg_quarters:.1f} quarters)")
    
    return qualifying_symbols


def load_data(filename: str = "data/metrics.json") -> List[dict]:
    """
    Load stock data from JSON file (metrics.json)
    
    Args:
        filename: Path to JSON file (default: metrics.json)
        
    Returns:
        List of stock data dictionaries
    """
    try:
        with open(filename, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: {filename} not found")
        return []
    except json.JSONDecodeError:
        print(f"Error: Invalid JSON in {filename}")
        return []


def extract_unified_data(data: List[dict], metric_keys: Optional[List[str]] = None) -> MetricData:
    """
    Extract metrics and forward return data into a unified MetricData structure.
    This is called once and the result is reused across all analysis functions.
    
    Args:
        data: List of stock data dictionaries
        metric_keys: List of metric keys to extract (if None, auto-detect from data)
        
    Returns:
        MetricData object containing all extracted data
    """
    metric_data = MetricData()
    
    # Auto-detect metric keys if not provided
    if metric_keys is None:
        metric_keys = []
        for stock in data:
            for entry in stock.get("data", []):
                for key, value in entry.items():
                    if key not in EXCLUDED_KEYS and value is not None and isinstance(value, (int, float)):
                        if key not in metric_keys:
                            metric_keys.append(key)
                break  # Only need to check one entry
    
    metric_data.metric_keys = metric_keys
    
    # Extract data grouped by time period and forward return period
    for stock in data:
        for entry in stock.get("data", []):
            time_period = entry.get("period")
            
            # Skip invalid periods
            if time_period is None or time_period == 0:
                continue
            
            # For each forward return period
            for forward_period in FORWARD_RETURN_PERIODS:
                forward_return_key = get_forward_return_key(forward_period)
                forward_return_value = entry.get(forward_return_key)
                
                # For each metric
                for metric_key in metric_keys:
                    metric_value = entry.get(metric_key)
                    
                    # Add valid data points (both metric and forward return must be valid)
                    if (metric_value is not None and forward_return_value is not None and 
                        isinstance(metric_value, (int, float)) and isinstance(forward_return_value, (int, float))):
                        metric_data.add_data_point(
                            forward_period, 
                            str(time_period), 
                            metric_key, 
                            float(metric_value), 
                            float(forward_return_value)
                        )
    
    return metric_data


def detect_available_metrics(data: List[dict]) -> dict:
    """
    Detect which metrics are available in the data
    
    Args:
        data: List of stock data dictionaries
    
    Returns:
        Dictionary mapping metric keys to their display names and descriptions
    """
    available_metrics = {}
    
    # First, find all potential metric keys by scanning all entries
    all_metric_keys = set()
    for stock in data:
        for entry in stock.get("data", []):
            for key, value in entry.items():
                if key not in EXCLUDED_KEYS:
                    # Check if it's a numeric value (could be a metric)
                    if value is not None and isinstance(value, (int, float)):
                        all_metric_keys.add(key)
    
    # Now check which of these have display names, or create default names
    for metric_key in sorted(all_metric_keys):
        if metric_key in METRIC_DISPLAY_NAMES:
            # Use the predefined display name
            available_metrics[metric_key] = METRIC_DISPLAY_NAMES[metric_key]
        else:
            # Create a default display name from the key
            # Convert snake_case to Title Case
            display_name = metric_key.replace('_', ' ').title()
            available_metrics[metric_key] = display_name
    
    return available_metrics


# ============================================================================
# ANALYSIS FUNCTIONS
# ============================================================================

def calculate_correlations(metric_values: List[float], forward_return_values: List[float]) -> dict:
    """
    Calculate correlation statistics between ranked metric values and ranked forward returns
    
    This function uses RANKED correlations (not absolute values):
    - Both metrics and forward returns are ranked from 1 to n
    - Correlation is calculated on the ranks, not the original values
    - This is equivalent to Spearman rank correlation
    
    Args:
        metric_values: List of metric values (e.g., ROA or EBIT/PPE)
        forward_return_values: List of forward return values
        
    Returns:
        Dictionary with correlation statistics (using ranked correlations)
    """
    
    if len(metric_values) < 2:
        return {
            "n_pairs": len(metric_values),
            "ranked_correlation": None,
            "ranked_pvalue": None,
            "error": "Insufficient data points for correlation"
        }
    
    # Convert to numpy arrays
    metric_array = np.array(metric_values)
    forward_return_array = np.array(forward_return_values)
    
    # Check if either array is constant (all values are the same)
    # If so, correlation is not defined
    if np.all(metric_array == metric_array[0]) or np.all(forward_return_array == forward_return_array[0]):
        return {
            "n_pairs": len(metric_values),
            "ranked_correlation": None,
            "ranked_pvalue": None,
            "error": "Constant input array - correlation not defined"
        }
    
    # Rank the data before correlating
    # Rankdata assigns ranks from 1 to n (where n = number of data points)
    # Average ranks are used for tied values
    # This converts absolute values to rankings
    metric_ranks = rankdata(metric_array, method='average')
    forward_return_ranks = rankdata(forward_return_array, method='average')
    
    # Check if ranks are constant (can happen if all values are tied)
    if np.all(metric_ranks == metric_ranks[0]) or np.all(forward_return_ranks == forward_return_ranks[0]):
        return {
            "n_pairs": len(metric_values),
            "ranked_correlation": None,
            "ranked_pvalue": None,
            "error": "Constant ranks - correlation not defined"
        }
    
    # Calculate correlation on RANKED data (not absolute values)
    # This measures how well the ranking of metrics predicts the ranking of returns
    # Suppress ConstantInputWarning since we already check for constant arrays above
    with warnings.catch_warnings():
        # Filter out ConstantInputWarning from scipy.stats.pearsonr
        # This warning is raised when input arrays are constant
        warnings.filterwarnings('ignore', message='.*An input array is constant.*')
        warnings.filterwarnings('ignore', message='.*constant.*')
        try:
            ranked_corr, ranked_p = pearsonr(metric_ranks, forward_return_ranks)
        except (ValueError, RuntimeWarning) as e:
            # Handle edge cases where correlation calculation fails
            return {
                "n_pairs": len(metric_values),
                "ranked_correlation": None,
                "ranked_pvalue": None,
                "error": f"Correlation calculation failed: {str(e)}"
            }
    
    return {
        "n_pairs": len(metric_values),
        "ranked_correlation": float(ranked_corr),
        "ranked_pvalue": float(ranked_p)
    }


def calculate_bucket_difference(pairs: List[Tuple[float, float]]) -> Optional[float]:
    """
    Calculate the difference between top 50% and bottom 50% bucket median returns.
    This is a shared function used by both ranking and buckets mode.
    
    Args:
        pairs: List of (metric_value, forward_return) tuples
    
    Returns:
        Difference between top and bottom bucket medians, or None if insufficient data
    """
    if len(pairs) < 2:
        return None
    
    metric_values = np.array([p[0] for p in pairs])
    forward_returns = np.array([p[1] for p in pairs])
    
    # Calculate median to split into top 50% and bottom 50%
    median_metric = np.median(metric_values)
    
    # Create masks for top and bottom 50%
    bottom_mask = metric_values <= median_metric
    top_mask = metric_values > median_metric
    
    bottom_returns = forward_returns[bottom_mask]
    top_returns = forward_returns[top_mask]
    
    if len(bottom_returns) > 0 and len(top_returns) > 0:
        bottom_median = np.median(bottom_returns)
        top_median = np.median(top_returns)
        return top_median - bottom_median
    
    return None


def calculate_bucket_difference_by_period(metric_data: MetricData, forward_period: str, metric_key: str) -> Optional[float]:
    """
    Calculate bucket difference by grouping points by period, calculating difference per period,
    then taking the median of all period differences.
    
    For each period:
    1. Find bottom 50% and top 50% of stocks for the metric
    2. Find median annualized total forward return for both top and bottom
    3. Calculate difference between these medians
    
    Then take the median of all period differences.
    
    Args:
        metric_data: MetricData object containing extracted data
        forward_period: Forward return period (e.g., 'total', '1y', '3y')
        metric_key: Metric key to analyze
    
    Returns:
        Median of period differences, or None if insufficient data
    """
    # Get all time periods for this forward period
    time_periods = metric_data.get_time_periods(forward_period)
    
    if not time_periods:
        return None
    
    period_differences = []
    
    # For each time period, calculate bucket difference
    for time_period in time_periods:
        pairs = metric_data.get_pairs(forward_period, metric_key, time_period)
        
        if len(pairs) < 2:
            continue
        
        # Calculate bucket difference for this period
        metric_values = np.array([p[0] for p in pairs])
        forward_returns = np.array([p[1] for p in pairs])
        
        # Calculate median to split into top 50% and bottom 50%
        median_metric = np.median(metric_values)
        
        # Create masks for top and bottom 50%
        bottom_mask = metric_values <= median_metric
        top_mask = metric_values > median_metric
        
        bottom_returns = forward_returns[bottom_mask]
        top_returns = forward_returns[top_mask]
        
        if len(bottom_returns) > 0 and len(top_returns) > 0:
            # Find median annualized total forward return for both top and bottom
            bottom_median = np.median(bottom_returns)
            top_median = np.median(top_returns)
            
            # Calculate difference between these medians
            period_diff = top_median - bottom_median
            period_differences.append(period_diff)
    
    # Take the median over all periods to get the final stat
    if len(period_differences) > 0:
        return np.median(period_differences)
    
    return None


def calculate_custom_bucket_stats(pairs: List[Tuple[float, float]], num_buckets: int) -> Optional[List[Dict]]:
    """
    Calculate median returns for custom number of buckets.
    
    Args:
        pairs: List of (metric_value, forward_return) tuples
        num_buckets: Number of buckets to split the data into
    
    Returns:
        List of dictionaries with bucket info (bucket_num, median_return, count), or None if insufficient data
    """
    if len(pairs) < num_buckets:
        return None
    
    metric_values = np.array([p[0] for p in pairs])
    forward_returns = np.array([p[1] for p in pairs])
    
    # Sort by metric value to create buckets
    sorted_indices = np.argsort(metric_values)
    sorted_returns = forward_returns[sorted_indices]
    
    # Calculate bucket sizes
    total_count = len(pairs)
    bucket_size = total_count / num_buckets
    
    bucket_stats = []
    for i in range(num_buckets):
        start_idx = int(i * bucket_size)
        end_idx = int((i + 1) * bucket_size) if i < num_buckets - 1 else total_count
        
        bucket_returns = sorted_returns[start_idx:end_idx]
        
        if len(bucket_returns) > 0:
            bucket_stats.append({
                'bucket_num': i + 1,
                'median_return': float(np.median(bucket_returns)),
                'count': len(bucket_returns)
            })
    
    return bucket_stats if bucket_stats else None


# ============================================================================
# RANKING FUNCTIONS
# ============================================================================

def rank_metrics_by_correlation(metric_data: MetricData, available_metrics: dict) -> List[Tuple[str, float]]:
    """
    Rank all metrics by their correlation with total forward return
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
    
    Returns:
        List of tuples (metric_key, correlation) sorted by correlation (descending)
    """
    forward_period = 'total'
    rankings = []
    
    for metric_key in available_metrics.keys():
        # Calculate correlations for each time period
        period_correlations = []
        period_weights = []
        
        time_periods = metric_data.get_time_periods(forward_period)
        
        for time_period in time_periods:
            pairs = metric_data.get_pairs(forward_period, metric_key, time_period)
            
            if len(pairs) >= 2:
                metric_values = [p[0] for p in pairs]
                forward_return_values = [p[1] for p in pairs]
                
                period_stat = calculate_correlations(metric_values, forward_return_values)
                ranked_corr = period_stat.get('ranked_correlation')
                
                if ranked_corr is not None:
                    period_correlations.append(ranked_corr)
                    period_weights.append(period_stat.get('n_pairs', 0))
        
        # Calculate weighted average correlation
        if period_correlations and period_weights:
            correlations_array = np.array(period_correlations)
            weights_array = np.array(period_weights)
            weighted_avg_correlation = np.average(correlations_array, weights=weights_array)
            rankings.append((metric_key, weighted_avg_correlation))
        else:
            rankings.append((metric_key, None))
    
    # Sort by correlation (descending), handling None values
    rankings.sort(key=lambda x: x[1] if x[1] is not None else float('-inf'), reverse=True)
    return rankings


def rank_metrics_by_bucket_difference(metric_data: MetricData, available_metrics: dict) -> List[Tuple[str, float]]:
    """
    Rank all metrics by the difference between top 50% and bottom 50% bucket returns.
    
    This function groups points by period, calculates bucket difference per period,
    then takes the median of all period differences.
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
    
    Returns:
        List of tuples (metric_key, difference) sorted by difference (descending)
    """
    forward_period = 'total'
    rankings = []
    
    for metric_key in available_metrics.keys():
        # Calculate bucket difference using per-period method
        difference = calculate_bucket_difference_by_period(metric_data, forward_period, metric_key)
        
        if difference is not None:
            rankings.append((metric_key, difference))
        else:
            rankings.append((metric_key, None))
    
    # Sort by difference (descending), handling None values
    rankings.sort(key=lambda x: x[1] if x[1] is not None else float('-inf'), reverse=True)
    return rankings


# ============================================================================
# DISPLAY FUNCTIONS
# ============================================================================

def display_rankings_by_correlation(rankings: List[Tuple[str, float]], available_metrics: dict):
    """Display metric rankings by correlation."""
    print("\n" + "="*100)
    print("Metric Rankings by Correlation (Total Forward Return)")
    print("="*100)
    print(f"\n{'Rank':<10} {'Metric':<50} {'Correlation':<20}")
    print("-"*100)
    for rank, (metric_key, score) in enumerate(rankings, start=1):
        metric_name = available_metrics.get(metric_key, metric_key)
        if score is not None:
            print(f"{rank:<10} {metric_name:<50} {score:<20.4f}")
        else:
            print(f"{rank:<10} {metric_name:<50} {'N/A':<20}")
    print("="*100)


def display_rankings_by_bucket_difference(rankings: List[Tuple[str, float]], available_metrics: dict):
    """Display metric rankings by bucket difference."""
    print("\n" + "="*100)
    print("Metric Rankings by Bucket Difference (Total Forward Return)")
    print("="*100)
    print(f"\n{'Rank':<10} {'Metric':<50} {'Top-Bottom Difference (%)':<30}")
    print("-"*100)
    for rank, (metric_key, score) in enumerate(rankings, start=1):
        metric_name = available_metrics.get(metric_key, metric_key)
        if score is not None:
            print(f"{rank:<10} {metric_name:<50} {score:<30.2f}")
        else:
            print(f"{rank:<10} {metric_name:<50} {'N/A':<30}")
    print("="*100)


def print_correlations_by_forward_period(results: dict, metric_name: str):
    """
    Print ranked correlation for each forward return period (1y, 3y, 5y, 10y) for a given metric
    
    Note: Correlations are calculated on RANKED values (not absolute values)
    
    Args:
        results: Dictionary mapping forward_return_period -> correlation results dict
        metric_name: Display name of the metric
    """
    print("\n" + "="*100)
    print(f"{metric_name} vs Forward Return Ranked Correlation by Forward Return Period")
    print("(Weighted average of ranked correlations across all time periods)")
    print("Note: Uses rankings of metrics and returns, not absolute values")
    print("="*100)
    print(f"\n{'Forward Period':<20} {'Ranked Corr':<15} {'p-value':<15} {'Significant':<15} {'N Pairs':<15} {'N Periods':<15}")
    print("-" * 100)
    
    for forward_period in FORWARD_RETURN_PERIODS:
        if forward_period in results:
            result = results[forward_period]
            ranked_corr = result.get('ranked_correlation')
            p_value = result.get('ranked_pvalue')
            n_pairs = result.get('n_pairs', 0)
            n_periods = result.get('n_periods', 0)
            
            if ranked_corr is not None and p_value is not None:
                is_significant = p_value < SIGNIFICANCE_THRESHOLD
                significance = "Yes" if is_significant else "No"
                period_display = format_forward_period_display(forward_period)
                print(f"{period_display:<20} {ranked_corr:<15.4f} {p_value:<15.4e} {significance:<15} {n_pairs:<15} {n_periods:<15}")
            else:
                period_display = format_forward_period_display(forward_period)
                print(f"{period_display:<20} {'N/A':<15} {'N/A':<15} {'N/A':<15} {n_pairs:<15} {n_periods:<15}")
    
    print("="*100)


def print_forward_period_correlations_summary(results: dict, metric_name: str):
    """
    Print summary statistics for ranked correlation results across forward return periods for a given metric
    
    Note: Correlations are calculated on RANKED values (not absolute values)
    
    Args:
        results: Dictionary mapping forward_return_period -> correlation results dict
        metric_name: Display name of the metric
    """
    if not results:
        return
    
    print("\n" + "="*100)
    print(f"{metric_name} vs Forward Return Ranked Correlation Summary")
    print("(Using rankings of metrics and returns, not absolute values)")
    print("="*100)
    
    significant_count = 0
    correlations = []
    weights = []  # Number of data points for each forward return period (for weighting)
    
    for forward_period in FORWARD_RETURN_PERIODS:
        if forward_period in results:
            result = results[forward_period]
            ranked_corr = result.get('ranked_correlation')
            p_value = result.get('ranked_pvalue')
            is_significant = p_value < SIGNIFICANCE_THRESHOLD if p_value is not None else False
            
            if is_significant:
                significant_count += 1
            if ranked_corr is not None:
                correlations.append(ranked_corr)
                weights.append(result.get('n_pairs', 0))  # Use number of data points as weight
    
    print("\nSummary Statistics Across Forward Return Periods (Ranked Correlations):")
    print(f"  Total forward return periods analyzed: {len([p for p in FORWARD_RETURN_PERIODS if p in results])}")
    print(f"  Periods with significant ranked correlation (p < {SIGNIFICANCE_THRESHOLD}): {significant_count}")
    if correlations:
        # Calculate weighted average correlation (weighted by number of data points)
        correlations_array = np.array(correlations)
        weights_array = np.array(weights)
        weighted_avg = np.average(correlations_array, weights=weights_array)
        
        print(f"  Average ranked correlation (unweighted): {np.mean(correlations):.4f}")
        print(f"  Weighted average ranked correlation (by data points): {weighted_avg:.4f}")
        print(f"  Median ranked correlation: {np.median(correlations):.4f}")
        print(f"  Min ranked correlation: {np.min(correlations):.4f}")
        print(f"  Max ranked correlation: {np.max(correlations):.4f}")
    print("="*100)


def print_period_correlations(period_stats: List[dict], metric_name: str):
    """
    Print ranked correlations for each individual time period (for total forward return only)
    
    Note: Correlations are calculated on RANKED values (not absolute values)
    
    Args:
        period_stats: List of correlation statistics dictionaries, each with 'time_period' key
        metric_name: Display name of the metric
    """
    if not period_stats:
        print("No period statistics available.")
        return
    
    print("\n" + "="*100)
    print(f"{metric_name} vs Total Forward Return Ranked Correlation by Time Period")
    print("(Using rankings of metrics and returns, not absolute values)")
    print("="*100)
    print(f"\n{'Time Period':<20} {'Ranked Corr':<15} {'p-value':<15} {'Significant':<15} {'N Pairs':<15}")
    print("-" * 100)
    
    # Sort by time period
    sorted_stats = sorted(period_stats, key=lambda x: x.get('time_period', 0))
    
    for stat in sorted_stats:
        time_period = stat.get('time_period', 'Unknown')
        ranked_corr = stat.get('ranked_correlation')
        p_value = stat.get('ranked_pvalue')
        n_pairs = stat.get('n_pairs', 0)
        
        if ranked_corr is not None and p_value is not None:
            is_significant = p_value < SIGNIFICANCE_THRESHOLD
            significance = "Yes" if is_significant else "No"
            print(f"{str(time_period):<20} {ranked_corr:<15.4f} {p_value:<15.4e} {significance:<15} {n_pairs:<15}")
        else:
            print(f"{str(time_period):<20} {'N/A':<15} {'N/A':<15} {'N/A':<15} {n_pairs:<15}")
    
    print("="*100)
    
    # Print summary statistics
    valid_correlations = [s.get('ranked_correlation') for s in sorted_stats 
                         if s.get('ranked_correlation') is not None]
    if valid_correlations:
        print(f"\nSummary Statistics Across Time Periods (Ranked Correlations):")
        print(f"  Total periods analyzed: {len(valid_correlations)}")
        significant_count = sum(1 for s in sorted_stats 
                               if s.get('ranked_pvalue') is not None and s.get('ranked_pvalue') < SIGNIFICANCE_THRESHOLD)
        print(f"  Periods with significant ranked correlation (p < {SIGNIFICANCE_THRESHOLD}): {significant_count}")
        print(f"  Average ranked correlation: {np.mean(valid_correlations):.4f}")
        print(f"  Median ranked correlation: {np.median(valid_correlations):.4f}")
        print(f"  Min ranked correlation: {np.min(valid_correlations):.4f}")
        print(f"  Max ranked correlation: {np.max(valid_correlations):.4f}")
        print("="*100)


# ============================================================================
# UI FUNCTIONS
# ============================================================================

def get_metric_combination_selection(available_metrics: dict) -> Optional[List[Tuple[str, int]]]:
    """
    Display metrics menu and get user's metric combination selection (e.g., "1+3" or "1-3")
    
    Args:
        available_metrics: Dictionary mapping metric keys to display names
    
    Returns:
        List of tuples (metric_key, sign) where sign is 1 for addition or -1 for subtraction,
        or None if user wants to exit
    """
    print("\n" + "="*80)
    print("Combine Metrics - Metric Selection")
    print("="*80)
    print("\nSelect which metrics to combine (e.g., type '1+3' to add, '1-3' to subtract):")
    print("  Use '+' to add metric ranks, '-' to subtract metric ranks")
    print("  Example: '1+3' adds ranks, '1-3' subtracts rank 3 from rank 1, '1+2-3' adds 1 and 2, then subtracts 3")
    
    metric_keys = sorted(available_metrics.keys())  # Sort for consistent ordering
    
    # Display metrics
    for i, metric_key in enumerate(metric_keys, start=1):
        print(f"  {i}. {available_metrics[metric_key]}")
    
    print("\n  'exit' - Exit")
    print("="*80)
    
    while True:
        try:
            choice = input("\nEnter metric numbers to combine (e.g., '1+3', '1-3', or '1+2-3'): ").strip().lower()
            
            if choice == 'exit':
                return None
            
            # Parse combination syntax (e.g., "1+3", "1-3", "1+2-3")
            # Split by + and - while preserving the operators
            # Match numbers with optional + or - prefix (first number may not have prefix)
            parts = re.findall(r'([+-]?)(\d+)', choice)
            
            if not parts:
                print("Invalid format. Please use format like '1+3', '1-3', or '1+2-3'.")
                continue
            
            selected_items = []
            for sign_str, num_str in parts:
                try:
                    idx = int(num_str)
                    if 1 <= idx <= len(metric_keys):
                        # Determine sign: + or no prefix = 1, - = -1
                        sign = -1 if sign_str == '-' else 1
                        selected_items.append((metric_keys[idx - 1], sign))
                    else:
                        print(f"Invalid metric number: {idx}. Please enter numbers between 1 and {len(metric_keys)}.")
                        break
                except ValueError:
                    print(f"Invalid number: {num_str}. Please enter valid metric numbers.")
                    break
            else:
                # All indices were valid
                if len(selected_items) > 0:
                    return selected_items
                else:
                    print("Please select at least one metric.")
        except KeyboardInterrupt:
            print("\n\nExiting...")
            return None
        except Exception as e:
            print(f"Error: {e}. Please try again.")


def get_num_buckets() -> Optional[int]:
    """
    Get the number of buckets from the user.
    
    Returns:
        Number of buckets as an integer, or None if user cancels
    """
    while True:
        try:
            choice = input("\nEnter number of buckets (must be >= 2): ").strip()
            
            if choice.lower() == 'exit':
                return None
            
            num_buckets = int(choice)
            
            if num_buckets < 2:
                print("Number of buckets must be at least 2. Please try again.")
                continue
            
            return num_buckets
            
        except ValueError:
            print("Invalid input. Please enter a valid number (>= 2) or 'exit'.")
        except KeyboardInterrupt:
            print("\n\nCancelling...")
            return None
        except Exception as e:
            print(f"Error: {e}. Please try again.")


def get_metric_selection(available_metrics: dict, mode: str = None, 
                        metric_data: Optional[MetricData] = None) -> str:
    """
    Display a dynamic menu and get user's metric selection
    
    Args:
        available_metrics: Dictionary mapping metric keys to display names
        mode: Current analysis mode ('average', 'buckets', etc.)
        metric_data: MetricData object (needed for rank functionality)
    
    Returns:
        String indicating selected metric(s) or 'exit'
    """
    print("\n" + "="*80)
    print("Correlation Analysis - Metric Selection")
    print("="*80)
    print("\nSelect which metric to analyze:")
    
    # Build menu dynamically based on available metrics
    menu_items = []
    metric_keys = sorted(available_metrics.keys())  # Sort for consistent ordering
    
    # Add individual metrics
    for i, metric_key in enumerate(metric_keys, start=1):
        menu_items.append((str(i), metric_key, available_metrics[metric_key]))
        print(f"  {i}. {available_metrics[metric_key]}")
    
    # Add "All metrics" option if more than one metric
    if len(metric_keys) > 1:
        menu_items.append((str(len(metric_keys) + 1), 'all', 'All metrics'))
        print(f"  {len(metric_keys) + 1}. All metrics")
    
    # Add "Rank metrics" option for average and buckets modes
    rank_option_num = len(metric_keys) + (2 if len(metric_keys) > 1 else 1)
    if mode in ['average', 'buckets'] and metric_data is not None:
        menu_items.append((str(rank_option_num), 'rank', 'Rank metrics'))
        print(f"  {rank_option_num}. Rank metrics")
        exit_num = rank_option_num + 1
    else:
        exit_num = rank_option_num
    
    # Add exit option
    menu_items.append((str(exit_num), 'exit', 'Exit'))
    print(f"  {exit_num}. Exit")
    
    print("="*80)
    
    max_choice = exit_num
    while True:
        try:
            choice = input(f"\nEnter your choice (1-{max_choice}): ").strip()
            
            # Find the menu item for this choice
            for num, key, _ in menu_items:
                if choice == num:
                    if key == 'rank':
                        # Show rankings using separate display functions
                        if mode == 'average':
                            rankings = rank_metrics_by_correlation(metric_data, available_metrics)
                            display_rankings_by_correlation(rankings, available_metrics)
                        elif mode == 'buckets':
                            rankings = rank_metrics_by_bucket_difference(metric_data, available_metrics)
                            display_rankings_by_bucket_difference(rankings, available_metrics)
                        
                        # After showing rankings, ask user to select a metric
                        print("\nSelect a metric from the rankings above:")
                        print("  Enter rank number (1, 2, 3, etc.) - Select that metric")
                        print("  'all' - Analyze all metrics")
                        print("  'exit' - Exit")
                        metric_choice = input("\nEnter rank number, 'all', or 'exit': ").strip().lower()
                        
                        if metric_choice == 'exit':
                            return 'exit'
                        elif metric_choice == 'all':
                            return 'all'
                        else:
                            # Try to find metric by rank number
                            try:
                                rank_idx = int(metric_choice) - 1
                                if 0 <= rank_idx < len(rankings):
                                    return rankings[rank_idx][0]
                                else:
                                    print(f"Invalid rank number. Please enter 1-{len(rankings)}, 'all', or 'exit'.")
                                    continue
                            except ValueError:
                                # Try to find by metric name or key
                                for metric_key, _ in rankings:
                                    if metric_choice == metric_key or metric_choice.lower() in available_metrics.get(metric_key, '').lower():
                                        return metric_key
                                print(f"Invalid selection. Please try again.")
                                continue
                    else:
                        return key
            
            print(f"Invalid choice. Please enter a number between 1 and {max_choice}.")
        except KeyboardInterrupt:
            print("\n\nExiting...")
            return 'exit'
        except Exception as e:
            print(f"Error: {e}. Please try again.")


def show_command_summary() -> str:
    """
    Display brief command summary and get user selection (used after each command completes)
    
    Returns:
        Selected command mode or 'exit'
    """
    print("\n" + "="*80)
    print("Available commands: 1. average  2. by-period  3. buckets  4. custom-bucket  5. combine  6. exit")
    print("="*80)
    
    while True:
        try:
            choice = input("\nEnter command (1-6) or command name: ").strip().lower()
            
            # Handle numeric choices
            if choice == '1' or choice == 'average':
                return 'average'
            
            elif choice == '2' or choice == 'by-period' or choice == 'byperiod':
                return 'by-period'
            
            elif choice == '3' or choice == 'buckets':
                return 'buckets'
            
            elif choice == '4' or choice == 'custom-bucket' or choice == 'custombucket':
                return 'custom-bucket'
            
            elif choice == '5' or choice == 'combine':
                return 'combine'
            
            elif choice == '6' or choice == 'exit':
                return 'exit'
            
            else:
                print(f"Invalid choice. Please enter 1-6, or a command name (average, by-period, buckets, custom-bucket, combine, exit).")
        except KeyboardInterrupt:
            print("\n\nExiting...")
            return 'exit'
        except Exception as e:
            print(f"Error: {e}. Please try again.")


def show_command_menu() -> str:
    """
    Display available commands menu and get user selection (full menu with descriptions)
    
    Returns:
        Selected command mode or 'exit'
    """
    print("\n" + "="*80)
    print("Correlation Analysis - Available Commands")
    print("="*80)
    print("\nAvailable commands:")
    print("  1. average         - Calculate weighted average correlation across all time periods")
    print("  2. by-period      - Show correlations for each individual time period")
    print("  3. buckets         - Show median return for top 50% and bottom 50% of metric values")
    print("  4. custom-bucket   - Show median return for custom number of buckets (you specify the number)")
    print("  5. combine         - Combine multiple metrics by adding/subtracting their rankings")
    print("  6. exit            - Exit the program")
    print("="*80)
    
    while True:
        try:
            choice = input("\nEnter command (1-6) or command name: ").strip().lower()
            
            # Handle numeric choices
            if choice == '1' or choice == 'average':
                return 'average'
            
            elif choice == '2' or choice == 'by-period' or choice == 'byperiod':
                return 'by-period'
            
            elif choice == '3' or choice == 'buckets':
                return 'buckets'
            
            elif choice == '4' or choice == 'custom-bucket' or choice == 'custombucket':
                return 'custom-bucket'
            
            elif choice == '5' or choice == 'combine':
                return 'combine'
            
            elif choice == '6' or choice == 'exit':
                return 'exit'
            
            else:
                print(f"Invalid choice. Please enter 1-6, or a command name (average, by-period, buckets, custom-bucket, combine, exit).")
        except KeyboardInterrupt:
            print("\n\nExiting...")
            return 'exit'
        except Exception as e:
            print(f"Error: {e}. Please try again.")


# ============================================================================
# MODE EXECUTION FUNCTIONS
# ============================================================================

def run_average_mode(metric_data: MetricData, available_metrics: dict, metric_keys_to_process: List[str]):
    """
    Run average correlation mode - calculates weighted average correlation across all time periods
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
        metric_keys_to_process: List of metric keys to analyze
    """
    print("\nCalculating correlations for each time period, then weighted average across periods...")
    all_results = {metric_key: {} for metric_key in metric_keys_to_process}
    
    for forward_period in FORWARD_RETURN_PERIODS:
        for metric_key in metric_keys_to_process:
            # Calculate correlations for each time period
            period_correlations = []
            period_weights = []  # Sample sizes for weighting
            period_stats = []  # Store full stats for each period
            
            # Get all time periods for this forward return period
            time_periods = metric_data.get_time_periods(forward_period)
            
            for time_period in time_periods:
                pairs = metric_data.get_pairs(forward_period, metric_key, time_period)
                
                if len(pairs) >= 2:
                    metric_values = [p[0] for p in pairs]
                    forward_return_values = [p[1] for p in pairs]
                    
                    period_stat = calculate_correlations(metric_values, forward_return_values)
                    ranked_corr = period_stat.get('ranked_correlation')
                    
                    if ranked_corr is not None:
                        period_correlations.append(ranked_corr)
                        period_weights.append(period_stat.get('n_pairs', 0))
                        period_stat['time_period'] = time_period
                        period_stats.append(period_stat)
            
            # Calculate weighted average correlation across all time periods
            if period_correlations and period_weights:
                correlations_array = np.array(period_correlations)
                weights_array = np.array(period_weights)
                weighted_avg_correlation = np.average(correlations_array, weights=weights_array)
                
                # Calculate weighted average p-value (using Fisher's z-transformation would be more accurate,
                # but for simplicity we'll use weighted average of p-values)
                period_pvalues = [s.get('ranked_pvalue') for s in period_stats if s.get('ranked_pvalue') is not None]
                if period_pvalues:
                    # Weight p-values by sample size (inverse weighting - larger samples get more weight)
                    pvalues_array = np.array(period_pvalues)
                    weighted_avg_pvalue = np.average(pvalues_array, weights=weights_array)
                else:
                    weighted_avg_pvalue = None
                
                # Total number of pairs across all periods
                total_pairs = sum(period_weights)
                
                # Create summary stats
                stats = {
                    'forward_period': forward_period,
                    'metric_key': metric_key,
                    'ranked_correlation': float(weighted_avg_correlation),
                    'ranked_pvalue': float(weighted_avg_pvalue) if weighted_avg_pvalue is not None else None,
                    'n_pairs': total_pairs,
                    'n_periods': len(period_correlations),
                    'period_correlations': period_correlations,  # Store for reference
                    'period_stats': period_stats  # Store full period stats
                }
                
                all_results[metric_key][forward_period] = stats
    
    # Display results for each selected metric
    for metric_key in metric_keys_to_process:
        results = all_results[metric_key]
        if results:
            metric_name = available_metrics.get(metric_key, metric_key)
            print_correlations_by_forward_period(results, metric_name)
    
    # Print summary statistics for each selected metric
    for metric_key in metric_keys_to_process:
        results = all_results[metric_key]
        if results:
            metric_name = available_metrics.get(metric_key, metric_key)
            print_forward_period_correlations_summary(results, metric_name)


def run_by_period_mode(metric_data: MetricData, available_metrics: dict, metric_keys_to_process: List[str]):
    """
    Run by-period correlation mode - shows correlations for each individual time period (total forward return only)
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
        metric_keys_to_process: List of metric keys to analyze
    """
    # Only analyze total forward return
    forward_period = 'total'
    
    print(f"\nCalculating correlations for each time period (total forward return only)...")
    
    for metric_key in metric_keys_to_process:
        period_stats = []
        
        # Get all time periods for total forward return
        time_periods = metric_data.get_time_periods(forward_period)
        
        for time_period in time_periods:
            pairs = metric_data.get_pairs(forward_period, metric_key, time_period)
            
            if len(pairs) >= 2:
                metric_values = [p[0] for p in pairs]
                forward_return_values = [p[1] for p in pairs]
                
                period_stat = calculate_correlations(metric_values, forward_return_values)
                ranked_corr = period_stat.get('ranked_correlation')
                
                if ranked_corr is not None:
                    period_stat['time_period'] = time_period
                    period_stats.append(period_stat)
        
        # Display results for this metric
        if period_stats:
            metric_name = available_metrics.get(metric_key, metric_key)
            print_period_correlations(period_stats, metric_name)
        else:
            metric_name = available_metrics.get(metric_key, metric_key)
            print(f"\nNo valid correlation data found for {metric_name}.")


def run_buckets_mode(metric_data: MetricData, available_metrics: dict, metric_keys_to_process: List[str]):
    """
    Run buckets mode - shows median return for top 50% and bottom 50% of metric values
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
        metric_keys_to_process: List of metric keys to analyze
    """
    # If processing all metrics, show a summary table
    if len(metric_keys_to_process) > 1:
        print("\n" + "="*100)
        print("All Metrics - Bucket Differences by Forward Return Period")
        print("="*100)
        print(f"\n{'Metric':<50} {'Total':<15} {'1y':<15} {'3y':<15} {'5y':<15} {'10y':<15}")
        print("-"*100)
        
        for metric_key in metric_keys_to_process:
            metric_name = available_metrics.get(metric_key, metric_key)
            
            # Calculate bucket difference for each forward period
            differences = []
            for forward_period in FORWARD_RETURN_PERIODS:
                difference = calculate_bucket_difference_by_period(metric_data, forward_period, metric_key)
                if difference is not None:
                    differences.append(f"{difference:.2f}%")
                else:
                    differences.append("N/A")
            
            print(f"{metric_name:<50} {differences[0]:<15} {differences[1]:<15} {differences[2]:<15} {differences[3]:<15} {differences[4]:<15}")
        
        print("="*100)
    else:
        # Single metric - show detailed view with top/bottom buckets
        for metric_key in metric_keys_to_process:
            metric_name = available_metrics.get(metric_key, metric_key)
            
            # Print results for each forward return period
            print("\n" + "="*100)
            print(f"{metric_name} - Median Return by Metric Buckets")
            print("="*100)
            print(f"\n{'Forward Period':<20} {'Bottom 50% Median Return':<30} {'Top 50% Median Return':<30} {'Difference':<20} {'N Points':<15}")
            print("-"*100)
            
            for forward_period in FORWARD_RETURN_PERIODS:
                # Use per-period bucket difference calculation
                difference = calculate_bucket_difference_by_period(metric_data, forward_period, metric_key)
                
                if difference is not None:
                    # For display, we still need to show the medians
                    # Get all pairs to calculate overall medians for display
                    pairs = metric_data.get_pairs(forward_period, metric_key)
                    
                    if len(pairs) >= 2:
                        metric_values = np.array([p[0] for p in pairs])
                        forward_returns = np.array([p[1] for p in pairs])
                        median_metric = np.median(metric_values)
                        bottom_mask = metric_values <= median_metric
                        top_mask = metric_values > median_metric
                        bottom_returns = forward_returns[bottom_mask]
                        top_returns = forward_returns[top_mask]
                        
                        bottom_median = np.median(bottom_returns)
                        top_median = np.median(top_returns)
                        
                        period_display = format_forward_period_display(forward_period)
                        print(f"{period_display:<20} {bottom_median:<30.2f}% {top_median:<30.2f}% {difference:<20.2f}% {len(pairs):<15,}")
            
            print("="*100)


def run_custom_buckets_mode(metric_data: MetricData, available_metrics: dict, metric_keys_to_process: List[str], num_buckets: int):
    """
    Run custom buckets mode - shows median return for custom number of buckets
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
        metric_keys_to_process: List of metric keys to analyze
        num_buckets: Number of buckets to split stocks into
    """
    for metric_key in metric_keys_to_process:
        metric_name = available_metrics.get(metric_key, metric_key)
        
        # Print results for each forward return period
        print("\n" + "="*100)
        print(f"{metric_name} - Median Return by Metric Buckets ({num_buckets} buckets)")
        print("="*100)
        
        # Create compact header with bucket columns (B1, B2, etc.)
        # Use fixed column widths to ensure vertical alignment (9 chars per bucket including space)
        header = f"{'Period':<20}"
        for i in range(1, num_buckets + 1):
            header += f"{'B' + str(i):>9}"
        header += f"{'N':>10}"
        print(header)
        print("(Values show difference vs overall median: +X.XX% or -X.XX%)")
        print("-"*100)
        
        for forward_period in FORWARD_RETURN_PERIODS:
            pairs = metric_data.get_pairs(forward_period, metric_key)
            
            if len(pairs) < num_buckets:
                continue
            
            # Calculate overall median return for this period
            forward_returns = np.array([p[1] for p in pairs])
            overall_median = float(np.median(forward_returns))
            
            # Calculate custom bucket stats
            bucket_stats = calculate_custom_bucket_stats(pairs, num_buckets)
            
            if bucket_stats is not None:
                period_display = format_forward_period_display(forward_period)
                row = f"{period_display:<20}"
                for stat in bucket_stats:
                    # Show only the difference from overall median
                    diff = stat['median_return'] - overall_median
                    # Format the entire value (sign + number + %) as one unit, right-aligned
                    # Use + sign for positive, - for negative, no space between sign and number
                    if diff >= 0:
                        value_str = f"+{diff:.2f}%"
                    else:
                        value_str = f"{diff:.2f}%"
                    row += f"{value_str:>9}"
                row += f"{len(pairs):>10,}"
                print(row)
        
        print("="*100)


def calculate_combined_scores(metric_data: MetricData, metric_items: List[Tuple[str, int]], 
                              forward_period: str) -> List[Tuple[float, float]]:
    """
    Calculate combined scores by adding/subtracting ranks of multiple metrics, then pair with forward returns.
    
    Process (as specified):
    1. For each time period (monthly over 25 years):
       a. Rank all values for metric 1 (e.g., ROA) within that period
       b. Rank all values for metric 2 (e.g., PE) within that period
       c. For each stock/period combination, add the ranks together
    2. This produces a combined score for each stock/period
    3. The combined scores can then be ranked for sorting into top/bottom buckets
    
    Matches data points by (time_period, forward_return) combination to ensure we're matching
    the same stock/period across different metrics.
    
    Args:
        metric_data: MetricData object containing extracted data
        metric_items: List of tuples (metric_key, sign) where sign is 1 for addition or -1 for subtraction
        forward_period: Forward return period to use
    
    Returns:
        List of (combined_score, forward_return) tuples
    """
    combined_pairs = []
    
    # Extract metric keys (needed for matching)
    metric_keys = [item[0] for item in metric_items]
    
    # Get all time periods
    time_periods = metric_data.get_time_periods(forward_period)
    
    for time_period in time_periods:
        # Step 1: Get all pairs for all metrics for this time period
        all_metric_pairs = {}
        for metric_key in metric_keys:
            pairs = metric_data.get_pairs(forward_period, metric_key, time_period)
            if len(pairs) > 0:
                all_metric_pairs[metric_key] = pairs
        
        if not all_metric_pairs or len(all_metric_pairs) < len(metric_keys):
            continue
        
        # Step 2: Rank each metric separately within this time period
        # For each metric, create a mapping: (metric_value, forward_return) -> rank
        metric_value_to_rank = {}
        
        for metric_key in metric_keys:
            if metric_key in all_metric_pairs:
                pairs = all_metric_pairs[metric_key]
                # Extract just the metric values for ranking
                metric_values = np.array([p[0] for p in pairs])
                # Rank all values for this metric within this time period
                ranks = rankdata(metric_values, method='average')
                
                # Create mapping from (metric_value, forward_return) to rank
                # This allows us to look up the rank for a specific data point
                metric_value_to_rank[metric_key] = {}
                for i, (mv, fr) in enumerate(pairs):
                    # Use a tuple key that's tolerant of floating point differences
                    key = (round(mv, 10), round(fr, 10))
                    metric_value_to_rank[metric_key][key] = ranks[i]
        
        # Step 3: Match data points across metrics by (time_period, forward_return)
        # Group by forward_return value within this time period
        # Structure: forward_return -> {metric_key: metric_value}
        forward_return_groups = {}
        
        for metric_key in metric_keys:
            if metric_key in all_metric_pairs:
                for metric_value, forward_return in all_metric_pairs[metric_key]:
                    # Round to handle floating point precision issues
                    fr_rounded = round(forward_return, 10)
                    if fr_rounded not in forward_return_groups:
                        forward_return_groups[fr_rounded] = {}
                    # Store the metric value for this forward_return
                    forward_return_groups[fr_rounded][metric_key] = metric_value
        
        # Step 4: For each matched data point (same forward_return = same stock/period),
        # calculate combined score by adding/subtracting ranks
        for forward_return, metric_values_dict in forward_return_groups.items():
            # Only process if all metrics are present for this data point
            if set(metric_values_dict.keys()) == set(metric_keys):
                # Calculate combined score by adding/subtracting ranks
                combined_score = 0.0
                all_ranks_found = True
                
                for metric_key, sign in metric_items:
                    metric_value = metric_values_dict[metric_key]
                    # Look up the rank for this metric value
                    key = (round(metric_value, 10), forward_return)
                    if metric_key in metric_value_to_rank and key in metric_value_to_rank[metric_key]:
                        rank = metric_value_to_rank[metric_key][key]
                        combined_score += sign * rank  # Add or subtract based on sign
                    else:
                        # Rank not found - skip this data point
                        all_ranks_found = False
                        break
                
                if all_ranks_found:
                    # Store the combined score paired with its forward return
                    combined_pairs.append((combined_score, forward_return))
    
    return combined_pairs


def run_combine_mode(metric_data: MetricData, available_metrics: dict):
    """
    Run combine mode - combines multiple metrics by adding/subtracting their ranks, then shows buckets.
    
    Args:
        metric_data: MetricData object containing extracted data
        available_metrics: Dictionary mapping metric keys to display names
    """
    # Get metric combination selection
    selected_metric_items = get_metric_combination_selection(available_metrics)
    
    if selected_metric_items is None or len(selected_metric_items) == 0:
        print("No metrics selected. Exiting.")
        return
    
    # Create display name for combined metrics
    metric_parts = []
    for metric_key, sign in selected_metric_items:
        metric_name = available_metrics.get(metric_key, metric_key)
        if sign == 1:
            metric_parts.append(metric_name)
        else:
            metric_parts.append(f"- {metric_name}")
    combined_name = " + ".join(metric_parts)
    
    print(f"\nCombining metrics: {combined_name}")
    print("Calculating combined scores (add/subtract ranks)...")
    
    # Print results for each forward return period
    print("\n" + "="*100)
    print(f"Combined Metrics ({combined_name}) - Median Return by Combined Score Buckets")
    print("="*100)
    print(f"\n{'Forward Period':<20} {'Bottom 50% Median Return':<30} {'Top 50% Median Return':<30} {'Difference':<20} {'N Points':<15}")
    print("-"*100)
    
    for forward_period in FORWARD_RETURN_PERIODS:
        # Calculate combined scores
        combined_pairs = calculate_combined_scores(metric_data, selected_metric_items, forward_period)
        
        if len(combined_pairs) < 2:
            continue
        
        # Use shared bucket calculation function
        difference = calculate_bucket_difference(combined_pairs)
        
        if difference is not None:
            # Calculate bucket medians for display
            combined_scores = np.array([p[0] for p in combined_pairs])
            forward_returns = np.array([p[1] for p in combined_pairs])
            median_score = np.median(combined_scores)
            bottom_mask = combined_scores <= median_score
            top_mask = combined_scores > median_score
            bottom_returns = forward_returns[bottom_mask]
            top_returns = forward_returns[top_mask]
            
            bottom_median = np.median(bottom_returns)
            top_median = np.median(top_returns)
            
            period_display = format_forward_period_display(forward_period)
            print(f"{period_display:<20} {bottom_median:<30.2f}% {top_median:<30.2f}% {difference:<20.2f}% {len(combined_pairs):<15,}")
    
    print("="*100)


# ============================================================================
# MAIN FUNCTION
# ============================================================================

def main():
    """
    Main function to calculate and display correlation analysis by period
    Supports five modes:
    1. average - weighted average correlation across all time periods
    2. by-period - correlations for each individual time period (total forward return only)
    3. buckets - median return for top/bottom 50% buckets
    4. custom-bucket - median return for custom number of buckets (user specifies number)
    5. combine - combine multiple metrics by summing their ranks, then show buckets
    """
    parser = argparse.ArgumentParser(
        description='Calculate correlation between metrics and forward returns',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""Examples:
  python correlations.py                    # Interactive menu
  python correlations.py average            # Average correlation across all periods
  python correlations.py by-period          # Show correlations for each time period
  python correlations.py buckets            # Show median return for top/bottom 50% buckets
  python correlations.py custom-bucket       # Show median return for custom number of buckets
  python correlations.py combine            # Combine multiple metrics by summing ranks
        """
    )
    parser.add_argument(
        'mode',
        choices=['average', 'by-period', 'buckets', 'custom-bucket', 'combine'],
        nargs='?',
        help='Analysis mode: "average" for weighted average across all periods, "by-period" for per-period correlations, "buckets" for median return by metric buckets, "custom-bucket" for custom number of buckets, "combine" for combining multiple metrics'
    )
    
    args = parser.parse_args()
    
    # If mode specified via command line, run once and exit (non-interactive)
    if args.mode is not None:
        mode = args.mode
        # Filter stocks by revenue > 1B
        qualifying_symbols = get_stocks_with_revenue_over_threshold(1_000_000_000)
        
        # Load data first to detect available metrics
        print("\nLoading data from data/metrics.json...")
        data = load_data("data/metrics.json")
        
        if not data:
            print("No data loaded. Exiting.")
            return
        
        # Filter data to only include stocks with revenue > 1B
        original_count = len(data)
        data = [stock for stock in data if stock.get("symbol", "").upper() in qualifying_symbols]
        print(f"Loaded data for {len(data)} stock(s) (filtered from {original_count} stocks with revenue > $1B)")
        
        # Detect available metrics
        available_metrics = detect_available_metrics(data)
        
        if not available_metrics:
            print("No metrics found in data. Exiting.")
            return
        
        # Extract data once - this is now reused across all functions
        print("\nExtracting metrics and forward return data...")
        metric_data = extract_unified_data(data, list(available_metrics.keys()))
        
        # Run the appropriate mode
        if mode == 'combine':
            run_combine_mode(metric_data, available_metrics)
        elif mode == 'custom-bucket':
            # Get number of buckets from user
            num_buckets = get_num_buckets()
            if num_buckets is None:
                print("Exiting program.")
                return
            
            # Get user's metric selection
            selected_metrics = get_metric_selection(available_metrics, mode, metric_data)
            
            if selected_metrics == 'exit':
                print("Exiting program.")
                return
            
            # Determine which metrics to process
            if selected_metrics == 'all':
                metric_keys_to_process = list(available_metrics.keys())
            else:
                metric_keys_to_process = [selected_metrics]
            
            # Run custom buckets mode
            run_custom_buckets_mode(metric_data, available_metrics, metric_keys_to_process, num_buckets)
        else:
            # Get user's metric selection for other modes
            selected_metrics = get_metric_selection(available_metrics, mode, metric_data)
            
            if selected_metrics == 'exit':
                print("Exiting program.")
                return
            
            # Determine which metrics to process
            if selected_metrics == 'all':
                metric_keys_to_process = list(available_metrics.keys())
            else:
                metric_keys_to_process = [selected_metrics]
            
            # Run the appropriate mode
            if mode == 'average':
                run_average_mode(metric_data, available_metrics, metric_keys_to_process)
            elif mode == 'by-period':
                run_by_period_mode(metric_data, available_metrics, metric_keys_to_process)
            elif mode == 'buckets':
                run_buckets_mode(metric_data, available_metrics, metric_keys_to_process)
        return
    
    # Interactive mode: loop until user exits
    # Filter stocks by revenue > 1B
    qualifying_symbols = get_stocks_with_revenue_over_threshold(1_000_000_000)
    
    # Load data first to detect available metrics
    print("\nLoading data from metrics.json...")
    data = load_data("metrics.json")
    
    if not data:
        print("No data loaded. Exiting.")
        return
    
    # Filter data to only include stocks with revenue > 1B
    original_count = len(data)
    data = [stock for stock in data if stock.get("symbol", "").upper() in qualifying_symbols]
    print(f"Loaded data for {len(data)} stock(s) (filtered from {original_count} stocks with revenue > $1B)")
    
    # Detect available metrics
    available_metrics = detect_available_metrics(data)
    
    if not available_metrics:
        print("No metrics found in data. Exiting.")
        return
    
    # Extract data once - this is now reused across all functions
    print("\nExtracting metrics and forward return data...")
    metric_data = extract_unified_data(data, list(available_metrics.keys()))
    
    # Show full menu first time
    first_time = True
    
    # Main loop: continue until user exits
    while True:
        # Show full menu first time, brief summary after
        if first_time:
            selected_mode = show_command_menu()
            first_time = False
        else:
            selected_mode = show_command_summary()
        
        if selected_mode == 'exit':
            print("Exiting program.")
            break
        
        mode = selected_mode
        
        # Run the appropriate mode
        if mode == 'combine':
            run_combine_mode(metric_data, available_metrics)
        elif mode == 'custom-bucket':
            # Get number of buckets from user
            num_buckets = get_num_buckets()
            if num_buckets is None:
                # User cancelled, go back to command menu
                continue
            
            # Get user's metric selection
            selected_metrics = get_metric_selection(available_metrics, mode, metric_data)
            
            if selected_metrics == 'exit':
                # User exited from metric selection, go back to command menu
                continue
            
            # Determine which metrics to process
            if selected_metrics == 'all':
                metric_keys_to_process = list(available_metrics.keys())
            else:
                metric_keys_to_process = [selected_metrics]
            
            # Run custom buckets mode
            run_custom_buckets_mode(metric_data, available_metrics, metric_keys_to_process, num_buckets)
        else:
            # Get user's metric selection for other modes
            selected_metrics = get_metric_selection(available_metrics, mode, metric_data)
            
            if selected_metrics == 'exit':
                # User exited from metric selection, go back to command menu
                continue
            
            # Determine which metrics to process
            if selected_metrics == 'all':
                metric_keys_to_process = list(available_metrics.keys())
            else:
                metric_keys_to_process = [selected_metrics]
            
            # Run the appropriate mode
            if mode == 'average':
                run_average_mode(metric_data, available_metrics, metric_keys_to_process)
            elif mode == 'by-period':
                run_by_period_mode(metric_data, available_metrics, metric_keys_to_process)
            elif mode == 'buckets':
                run_buckets_mode(metric_data, available_metrics, metric_keys_to_process)


if __name__ == "__main__":
    main()
